{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "//MACRO TO DEBUG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "#endif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORAhs32kc0xk",
        "outputId": "bd64af39-2185-45fb-e167-4eea2c437dc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison on size, blocks and threads"
      ],
      "metadata": {
        "id": "3FzlgLbZreFB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1CXQEp-FjsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53094b0d-5308-4a3b-bf90-171613deae4b"
      },
      "source": [
        "%%writefile saxpy.cu\n",
        "/*\n",
        " * GPU code of SAPXPY\n",
        " * Y = a.X + Y\n",
        " */\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Vector initialization\n",
        "////////////////////////////////////////////////////////////////\n",
        "void init_tab(float *tab, int len, float val) {\n",
        "    for (int k=0; k<len; k++)\n",
        "      tab[k]= val;\n",
        "}\n",
        "\n",
        "void print_tab(const char *tab_name, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\n 10 first elements of %s: \\n\", tab_name);\n",
        "   for (k=0; k<10; k++)\n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\n 10 lasts : \\n\");\n",
        "   for (k=len-10; k<len; k++)\n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     SAXPY kernel\n",
        "////////////////////////////////////////////////////////////////\n",
        "__global__ void saxpy(float *tabX, float *tabY, int len, float a){\n",
        "   // TODO\n",
        "   int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "   if(idx < len)\n",
        "     tabY[idx] = a * tabX[idx] + tabY[idx];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Main program\n",
        "////////////////////////////////////////////////////////////////\n",
        "int main( int argc, char** argv){\n",
        "    float *tabX_d, *tabX_h;\n",
        "    float *tabY_d, *tabY_h;\n",
        "    int len_count = 3;\n",
        "    int lens[len_count] = {1000, 10000, 100000};\n",
        "    int num_threads[len_count] = {256, 512, 1024};\n",
        "\n",
        "    for (int i=0; i<len_count; i++){\n",
        "        int len = lens[i];\n",
        "        for (int j=0; j<len_count; j++){\n",
        "            int num_thread = num_threads[j];\n",
        "\n",
        "            cudaEvent_t start, stop;\n",
        "            float milliseconds = 0.0;\n",
        "            gpuErrchk(cudaEventCreate(&start));\n",
        "            gpuErrchk(cudaEventCreate(&stop));\n",
        "\n",
        "            /** Initialization of the grid **/\n",
        "            // TODO\n",
        "            dim3 dimBlock (num_thread);\n",
        "            dim3 dimGrid( ceil(len / (float) dimBlock.x) );\n",
        "\n",
        "            /** Allocation in host memory **/\n",
        "            tabX_h = (float *) malloc(sizeof(float) * len);\n",
        "            init_tab(tabX_h, len , 5.);\n",
        "            //TODO - allocation and initialization of tabY_dh\n",
        "            tabY_h = (float *) malloc(sizeof(float) * len);\n",
        "            init_tab(tabY_h, len, 1.);\n",
        "\n",
        "            /** Allocation in device memory **/\n",
        "            gpuErrchk(cudaMalloc((void**) &tabX_d, sizeof(float) * len));\n",
        "            // TODO - allocation of tabY_d\n",
        "            gpuErrchk(cudaMalloc((void**) &tabY_d, sizeof(float) * len));\n",
        "\n",
        "\n",
        "            /** Pre-print of tabY **/\n",
        "            printf(\"Array length: %d\\n\", len);\n",
        "            printf(\"Number of threads: %d\\n\", num_thread);\n",
        "            printf(\"Number of blocks: %d\\n\", dimGrid.x);\n",
        "            //printf(\"\\nBefore computation \\n\");\n",
        "            //print_tab(\"tabY_h\", tabY_h, len);\n",
        "\n",
        "\n",
        "            /** Transfer of data from host to device **/\n",
        "            // TODO\n",
        "            gpuErrchk(cudaMemcpy(tabX_d, tabX_h, sizeof(float) * len, cudaMemcpyHostToDevice));\n",
        "            gpuErrchk(cudaMemcpy(tabY_d, tabY_h, sizeof(float) * len, cudaMemcpyHostToDevice));\n",
        "\n",
        "            /** SaxPY kernel launching **/\n",
        "            //TODO\n",
        "            gpuErrchk(cudaEventRecord(start));\n",
        "            saxpy<<<dimGrid, dimBlock>>>(tabX_d, tabY_d, len, 2.);\n",
        "            gpuErrchk( cudaPeekAtLastError() );\n",
        "            gpuErrchk( cudaDeviceSynchronize() );\n",
        "            gpuErrchk(cudaEventRecord(stop));\n",
        "            gpuErrchk(cudaEventSynchronize(stop));\n",
        "            gpuErrchk(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "\n",
        "            /** Transfer of the result from device to host **/\n",
        "            // TODO\n",
        "            gpuErrchk(cudaMemcpy(tabY_h, tabY_d, sizeof(float) * len, cudaMemcpyDeviceToHost));\n",
        "\n",
        "            /** Affichage du resultat **/\n",
        "            //printf(\"\\nAfter computation\\n\");\n",
        "            //print_tab(\"tabY_h\", tabY_h, len);\n",
        "\n",
        "            /** Memory free **/\n",
        "            gpuErrchk(cudaFree(tabX_d)); gpuErrchk(cudaFree(tabY_d));\n",
        "            free(tabX_h); free(tabY_h);\n",
        "\n",
        "            printf(\"\\nExecution time: %f ms\\n\", milliseconds);\n",
        "            printf(\"\\n-----------------------\\n\\n\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing saxpy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc -arch=sm_75 saxpy.cu -o saxpy"
      ],
      "metadata": {
        "id": "UF-GcylqnMF9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./saxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC4QYWkfnTLQ",
        "outputId": "bb92e785-0bfa-4cb3-c0ad-310d2426effa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array length: 1000\n",
            "Number of threads: 256\n",
            "Number of blocks: 4\n",
            "\n",
            "Execution time: 0.147232 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 1000\n",
            "Number of threads: 512\n",
            "Number of blocks: 2\n",
            "\n",
            "Execution time: 0.020128 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 1000\n",
            "Number of threads: 1024\n",
            "Number of blocks: 1\n",
            "\n",
            "Execution time: 0.018240 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 10000\n",
            "Number of threads: 256\n",
            "Number of blocks: 40\n",
            "\n",
            "Execution time: 0.012384 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 10000\n",
            "Number of threads: 512\n",
            "Number of blocks: 20\n",
            "\n",
            "Execution time: 0.014592 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 10000\n",
            "Number of threads: 1024\n",
            "Number of blocks: 10\n",
            "\n",
            "Execution time: 0.013024 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 100000\n",
            "Number of threads: 256\n",
            "Number of blocks: 391\n",
            "\n",
            "Execution time: 0.017728 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 100000\n",
            "Number of threads: 512\n",
            "Number of blocks: 196\n",
            "\n",
            "Execution time: 0.021120 ms\n",
            "\n",
            "-----------------------\n",
            "\n",
            "Array length: 100000\n",
            "Number of threads: 1024\n",
            "Number of blocks: 98\n",
            "\n",
            "Execution time: 0.018048 ms\n",
            "\n",
            "-----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "\n",
        "Using 1024 threads per block is optimal for every lenght of the array. The difference between threads per block is decreased as the length of the array decreases."
      ],
      "metadata": {
        "id": "ZBtwwprntb8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison CPU vs GPU"
      ],
      "metadata": {
        "id": "Yo_4EPqAtZjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile saxpy.cu\n",
        "/*\n",
        " * GPU code of SAPXPY\n",
        " * Y = a.X + Y\n",
        " */\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <math.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Vector initialization\n",
        "////////////////////////////////////////////////////////////////\n",
        "void init_tab(float *tab, int len, float val) {\n",
        "    for (int k=0; k<len; k++)\n",
        "      tab[k]= val;\n",
        "}\n",
        "\n",
        "void print_tab(const char *tab_name, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\n 10 first elements of %s: \\n\", tab_name);\n",
        "   for (k=0; k<10; k++)\n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\n 10 lasts : \\n\");\n",
        "   for (k=len-10; k<len; k++)\n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     CPU SAXPY implementation\n",
        "////////////////////////////////////////////////////////////////\n",
        "void saxpy_cpu(float *tabX, float *tabY, int len, float a) {\n",
        "    for (int i = 0; i < len; i++) {\n",
        "        tabY[i] = a * tabX[i] + tabY[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     SAXPY kernel\n",
        "////////////////////////////////////////////////////////////////\n",
        "__global__ void saxpy(float *tabX, float *tabY, int len, float a){\n",
        "   // TODO\n",
        "   int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "   if(idx < len)\n",
        "     tabY[idx] = a * tabX[idx] + tabY[idx];\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Get current time in milliseconds\n",
        "////////////////////////////////////////////////////////////////\n",
        "double get_time_ms() {\n",
        "    struct timeval tv;\n",
        "    gettimeofday(&tv, NULL);\n",
        "    return tv.tv_sec * 1000.0 + tv.tv_usec / 1000.0;\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Main program\n",
        "////////////////////////////////////////////////////////////////\n",
        "int main( int argc, char** argv){\n",
        "    float *tabX_d, *tabX_h, *tabX_cpu;\n",
        "    float *tabY_d, *tabY_h, *tabY_cpu;\n",
        "    int len_count = 3;\n",
        "    int lens[len_count] = {1000, 10000, 100000};\n",
        "\n",
        "    for (int i=0; i<len_count; i++){\n",
        "        int len = lens[i];\n",
        "\n",
        "        /** CPU computation **/\n",
        "        tabX_cpu = (float *) malloc(sizeof(float) * len);\n",
        "        init_tab(tabX_cpu, len, 5.);\n",
        "        tabY_cpu = (float *) malloc(sizeof(float) * len);\n",
        "        init_tab(tabY_cpu, len, 1.);\n",
        "\n",
        "        double cpu_start = get_time_ms();\n",
        "        saxpy_cpu(tabX_cpu, tabY_cpu, len, 2.);\n",
        "        double cpu_stop = get_time_ms();\n",
        "        float cpu_milliseconds = cpu_stop - cpu_start;\n",
        "\n",
        "        cudaEvent_t gpu_start, gpu_stop;\n",
        "        float gpu_milliseconds = 0.0;\n",
        "        gpuErrchk(cudaEventCreate(&gpu_start));\n",
        "        gpuErrchk(cudaEventCreate(&gpu_stop));\n",
        "\n",
        "        /** Initialization of the grid **/\n",
        "        // TODO\n",
        "        dim3 dimBlock (1024);\n",
        "        dim3 dimGrid( ceil(len / (float) dimBlock.x) );\n",
        "\n",
        "        /** Allocation in host memory **/\n",
        "        tabX_h = (float *) malloc(sizeof(float) * len);\n",
        "        init_tab(tabX_h, len , 5.);\n",
        "        //TODO - allocation and initialization of tabY_dh\n",
        "        tabY_h = (float *) malloc(sizeof(float) * len);\n",
        "        init_tab(tabY_h, len, 1.);\n",
        "\n",
        "        /** Allocation in device memory **/\n",
        "        gpuErrchk(cudaMalloc((void**) &tabX_d, sizeof(float) * len));\n",
        "        // TODO - allocation of tabY_d\n",
        "        gpuErrchk(cudaMalloc((void**) &tabY_d, sizeof(float) * len));\n",
        "\n",
        "\n",
        "        /** Pre-print of tabY **/\n",
        "        printf(\"Array length: %d\\n\", len);\n",
        "        printf(\"Number of threads: %d\\n\", dimBlock.x);\n",
        "        printf(\"Number of blocks: %d\\n\", dimGrid.x);\n",
        "        //printf(\"\\nBefore computation \\n\");\n",
        "        //print_tab(\"tabY_h\", tabY_h, len);\n",
        "\n",
        "\n",
        "        /** Transfer of data from host to device **/\n",
        "        // TODO\n",
        "        gpuErrchk(cudaMemcpy(tabX_d, tabX_h, sizeof(float) * len, cudaMemcpyHostToDevice));\n",
        "        gpuErrchk(cudaMemcpy(tabY_d, tabY_h, sizeof(float) * len, cudaMemcpyHostToDevice));\n",
        "\n",
        "        /** SaxPY kernel launching **/\n",
        "        //TODO\n",
        "        gpuErrchk(cudaEventRecord(gpu_start));\n",
        "        saxpy<<<dimGrid, dimBlock>>>(tabX_d, tabY_d, len, 2.);\n",
        "        gpuErrchk( cudaPeekAtLastError() );\n",
        "        gpuErrchk( cudaDeviceSynchronize() );\n",
        "        gpuErrchk(cudaEventRecord(gpu_stop));\n",
        "        gpuErrchk(cudaEventSynchronize(gpu_stop));\n",
        "        gpuErrchk(cudaEventElapsedTime(&gpu_milliseconds, gpu_start, gpu_stop));\n",
        "\n",
        "        /** Transfer of the result from device to host **/\n",
        "        // TODO\n",
        "        gpuErrchk(cudaMemcpy(tabY_h, tabY_d, sizeof(float) * len, cudaMemcpyDeviceToHost));\n",
        "\n",
        "        /** Affichage du resultat **/\n",
        "        //printf(\"\\nAfter computation\\n\");\n",
        "        //print_tab(\"tabY_h\", tabY_h, len);\n",
        "\n",
        "        /** Memory free **/\n",
        "        gpuErrchk(cudaFree(tabX_d)); gpuErrchk(cudaFree(tabY_d));\n",
        "        free(tabX_h); free(tabY_h);\n",
        "\n",
        "        printf(\"\\nExecution time:\\n\");\n",
        "        printf(\"CPU: %f ms, GPU: %f ms\", cpu_milliseconds, gpu_milliseconds);\n",
        "        printf(\"\\n-----------------------\\n\\n\");\n",
        "    }\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov8nLJzJk9WL",
        "outputId": "979426ad-077c-4201-d098-a2d88fbdf307"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting saxpy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc -arch=sm_75 saxpy.cu -o saxpy"
      ],
      "metadata": {
        "id": "Y7l2EwnswUNy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./saxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihjH5jHiwUhz",
        "outputId": "52648a51-04cc-412e-93d8-0ecf7d587741"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array length: 1000\n",
            "Number of threads: 1024\n",
            "Number of blocks: 1\n",
            "\n",
            "Execution time:\n",
            "CPU: 0.003906 ms, GPU: 0.149152 ms\n",
            "-----------------------\n",
            "\n",
            "Array length: 10000\n",
            "Number of threads: 1024\n",
            "Number of blocks: 10\n",
            "\n",
            "Execution time:\n",
            "CPU: 0.038086 ms, GPU: 0.017696 ms\n",
            "-----------------------\n",
            "\n",
            "Array length: 100000\n",
            "Number of threads: 1024\n",
            "Number of blocks: 98\n",
            "\n",
            "Execution time:\n",
            "CPU: 0.307861 ms, GPU: 0.023296 ms\n",
            "-----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "\n",
        "The execution time with CPU is proportional to the length of the array. On the other hand, the GPU execution times stay constant (regardless of length increase)."
      ],
      "metadata": {
        "id": "9LTXqZZ6wotf"
      }
    }
  ]
}